{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Lighthouse Labs\n",
    "### W05D1 Training and Evaluation\n",
    "\n",
    "\n",
    "Instructor: Socorro Dominguez  \n",
    "July 19, 2021"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Overview\n",
    "- Training models\n",
    "    - Overfitting\n",
    "    - Train-test split\n",
    "    - Sampling bias\n",
    "    - Cross-validation\n",
    "    - Hyperparameter tuning\n",
    "        - Grid search\n",
    "- Model evaluation\n",
    "    - Regression\n",
    "    - Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns; sns.set(style='darkgrid', context='talk')\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Suppress some warnings that sklearn is returning when a model doesn't perform well\n",
    "from warnings import simplefilter\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "simplefilter(\"ignore\", category=ConvergenceWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Training models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "## Overfitting\n",
    "\n",
    "\n",
    "- Imagine studying for an exam using a set of practice questions\n",
    "- If you do well on the practice questions, are you guaranteed to do well on the real exam?\n",
    "- Goal is to *learn the underlying concepts* rather than *memorize the questions/answers*\n",
    "- This is called **generalization**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![](images/overfitting.png)\n",
    "- Data has two components: signal (pattern) + noise\n",
    "- Example: predicting house prices from # of bedrooms, area, age, etc.\n",
    "    - Signal: degree to which these features influence the price\n",
    "    - Noise: random variation, or variation due to unknown features\n",
    "- When the model is fitting the noise, it is overfitting\n",
    "- Overfitting is undesirable: noise is random and doesn't behave the same on new data.\n",
    "- **Why** does overfitting happen? Too complex."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Test/train split\n",
    "\n",
    "\n",
    "- If you were studying from practice exams, what would you do to get an idea of how you will perform on the real one?\n",
    "- Idea:\n",
    "    1. Learn from some practice exams that you do again and again (training data)\n",
    "    2. Write a *new* practice exam that you left to the side (test data)\n",
    "- This strategy will give you an idea of how well you will generalize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "\n",
    "- With more powerful models, we can always arbitrarily fit the training data better and better (lower training error)\n",
    "- What we're actually trying to achieve is good performance on **new data that our model was never trained on**\n",
    "- We can train our model on just a subset of our whole dataset (**train set**) and evaluate its performance on the rest (**test set**)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"images/test_set.png\" style=\"width: 700px;\"/>\n",
    "\n",
    "![](images/overfitting_training.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Train/test split example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset has 506 data points and 13 features\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "boston_data = load_boston()\n",
    "X, y = boston_data['data'], boston_data['target']\n",
    "\n",
    "# It is good practice to shuffle your data, since it\n",
    "# may be ordered in a particular way (e.g. increasing target)\n",
    "X, y = shuffle(X, y, random_state=27)\n",
    "\n",
    "print(f'Dataset has {X.shape[0]} data points and {X.shape[1]} features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "354 training samples and 152 test samples\n"
     ]
    }
   ],
   "source": [
    "# Make train/test split\n",
    "# Let's use 70% of the data for training and evaluate on the remaining 30%\n",
    "train_ratio = 0.7\n",
    "\n",
    "X_train, X_test = X[:int(train_ratio * len(X))], X[int(train_ratio * len(X)):]\n",
    "y_train, y_test = y[:int(train_ratio * len(y))], y[int(train_ratio * len(y)):]\n",
    "\n",
    "print(f'{len(X_train)} training samples and {len(X_test)} test samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "354 training samples and 152 test samples\n"
     ]
    }
   ],
   "source": [
    "# In practice, we can just use sklearn's convenience function for making the above split instead\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, shuffle=False, train_size=train_ratio)\n",
    "\n",
    "print(f'{len(X_train)} training samples and {len(X_test)} test samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train our model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "reg = LinearRegression()\n",
    "reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train R^2:\t0.7278481991105032\n",
      "Test R^2:\t0.7500070318143862\n"
     ]
    }
   ],
   "source": [
    "# Check performance on train and test set\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "y_train_pred = reg.predict(X_train)\n",
    "y_test_pred = reg.predict(X_test)\n",
    "\n",
    "r2_train = r2_score(y_train, y_train_pred)\n",
    "r2_test = r2_score(y_test, y_test_pred)\n",
    "\n",
    "print(f'Train R^2:\\t{r2_train}\\n\\\n",
    "Test R^2:\\t{r2_test}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Debrief\n",
    "The test set performance is actually *similar* to the train set. Our model doesn't seem to be overfitting.\n",
    "\n",
    "But the score is low... Perhaps we can use a more complex model and get even better performance on the test set. Let's try polynomial regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of polynomial features: 105\n",
      "Train R^2:\t0.9295292900269387\n",
      "Test R^2:\t0.8343842458230977\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "# Create polynomial feature set and train model\n",
    "polinomial = PolynomialFeatures(degree=2)\n",
    "\n",
    "Xpoly_train = polinomial.fit_transform(X_train)\n",
    "Xpoly_test = polinomial.transform(X_test)\n",
    "\n",
    "print(f'Number of polynomial features: {Xpoly_train.shape[1]}')\n",
    "\n",
    "# Predictions\n",
    "reg.fit(Xpoly_train, y_train)\n",
    "ypoly_train_pred = reg.predict(Xpoly_train)\n",
    "ypoly_test_pred = reg.predict(Xpoly_test)\n",
    "\n",
    "# Check performance on train and test set\n",
    "r2poly_train = r2_score(y_train, ypoly_train_pred)\n",
    "r2poly_test = r2_score(y_test, ypoly_test_pred)\n",
    "print(f'Train R^2:\\t{r2poly_train}\\nTest R^2:\\t{r2poly_test}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Our more complex second-order polynomial regression model performed even better on the test set.\n",
    "Our model might be overfitting, but we are not sure yet.\n",
    "Let's bump up the complexity one more time and try 4-order polynomial regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of polynomial features: 2380\n",
      "Train R^2:\t1.0\n",
      "Test R^2:\t-224.91117921662797\n"
     ]
    }
   ],
   "source": [
    "# Create polynomial feature set and train model\n",
    "poly4 = PolynomialFeatures(degree=4)\n",
    "Xpoly3_train = poly4.fit_transform(X_train)\n",
    "Xpoly3_test = poly4.transform(X_test)\n",
    "print(f'Number of polynomial features: {Xpoly3_train.shape[1]}')\n",
    "\n",
    "# Train our model\n",
    "reg.fit(Xpoly3_train, y_train)\n",
    "ypoly3_train_pred = reg.predict(Xpoly3_train)\n",
    "ypoly3_test_pred = reg.predict(Xpoly3_test)\n",
    "\n",
    "# Check performance on train and test set\n",
    "r2poly3_train = r2_score(y_train, ypoly3_train_pred)\n",
    "r2poly3_test = r2_score(y_test, ypoly3_test_pred)\n",
    "print(f'Train R^2:\\t{r2poly3_train}\\nTest R^2:\\t{r2poly3_test}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Our more complex 4-order polynomial regression model did horribly on the test set. Notice that it overfits the training set completly (perfect prediction). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Show performance of all models on train and test set\n",
    "df = pd.DataFrame({'Model Complexity': ['linear', 'linear', '2nd-order', '2nd-order', '4th-order', '4th-order'],\n",
    "                  'R^2': [r2_train, r2_test, r2poly_train, r2poly_test, r2poly3_train, r2poly3_test],\n",
    "                  'Set': ['train', 'test', 'train', 'test', 'train', 'test']})\n",
    "df['R^2'] = df['R^2'].clip(lower=0)    # Threshold minimum R^2 to 0 for nicer display of results (if it's 0, we already know it learned nothing)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.lineplot(x='Model Complexity', y='R^2', hue='Set', data=df, sort=False)\n",
    "plt.ylim(ymin=0, ymax=1)\n",
    "plt.ylabel('R^2 (higher is better)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Sampling bias\n",
    "\n",
    "- Remember that the model just learns patterns in the data you give it.\n",
    "- If our dataset isn't representative of the type of data we want our model to handle afterwards, it is not going to perform well.\n",
    "- Most machine learning models fail dramatically for **out of distribution** data that is very different from what we've trained on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "\n",
    "### Activity\n",
    "Think of a **dataset** and machine learning **task** where:\n",
    "- Our data was collected within a certain distribution (e.g. house prices in Toronto)\n",
    "- We evaluate it on out of distribution data where it would fail (e.g. house prices in Tokyo)\n",
    "\n",
    "Essentially **all** datasets are biased one way or another. Train yourself to think of different ways\n",
    "that they could be biased and different reasons why. Understanding the conditions under which your model\n",
    "will work and fail is essential when deploying it in the real world.\n",
    "\n",
    "*Try and think creatively about real scenarios where the dataset would be biased because of where it came from!\n",
    "(e.g. don't just say it only had house prices from Toronto, give a realistic explanation for why that might happen)*\n",
    "\n",
    "<!--\n",
    "- Old dataset from another decade\n",
    "- One data-source (e.g. Creg's list). Very common problem which will cause bias from multiple sources. Instagram selfie example from ModiFace\n",
    "- Different data processing (e.g. you forget to standardize the new data coming in like you did with your training data)\n",
    "- Different data formats or devices. For images, different cameras. For audio, different microphones. For text, different writing medium\n",
    "- Dataset too small (most common problem, since statistically small dataset is bound to be biased). Problem gets worse the more features we have\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Cross-validation\n",
    "- We wish to evaluate our model on a dataset with little sampling bias, so that we know how it will perform in the real world\n",
    "- Smaller datasets are far more likely to suffer from sampling bias\n",
    "- This creates a conflict:\n",
    "    - We want to have a big test set to get a realistic estimate of our model's performance without sampling bias\n",
    "    - We want to have a big training set so that our model can learn without sampling bias\n",
    "- How can we reconcile these goals?\n",
    "- **One answer:** cross-validation. Even if any single fold suffers from sampling bias, at least we are averaging the results from many"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "<img src=\"images/cross_validation.png\" style=\"width: 1000px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Cross-validation example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The folds are of type <class 'list'> and contain 102, 101, 101, 101, 101 data points\n"
     ]
    }
   ],
   "source": [
    "# Make the folds\n",
    "k_folds = 5\n",
    "\n",
    "X_folds, y_folds = np.array_split(X, k_folds), np.array_split(y, k_folds)\n",
    "\n",
    "fold_sizes = ', '.join([str(len(f)) for f in X_folds])\n",
    "print(f'The folds are of type {type(X_folds)} and contain {fold_sizes} data points')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7057189451172963, 0.6566041936444882, 0.7203026852522953, 0.7898705155348587, 0.7287877060675566]\n"
     ]
    }
   ],
   "source": [
    "# List that will accumulate test performance on each fold\n",
    "cv_r2 = []\n",
    "\n",
    "for i in range(k_folds):\n",
    "    # Make the train/test set for this fold\n",
    "    X_test = X_folds[i]\n",
    "    y_test = y_folds[i]\n",
    "    X_train = [X_folds[j] for j in range(k_folds) if j != i]\n",
    "    y_train = [y_folds[j] for j in range(k_folds) if j != i]\n",
    "    X_train = np.concatenate(X_train)\n",
    "    y_train = np.concatenate(y_train)\n",
    "    \n",
    "    # Train the model\n",
    "    reg.fit(X_train, y_train)\n",
    "    \n",
    "    # Evaluate the model on the test set\n",
    "    y_pred = reg.predict(X_test)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    cv_r2.append(r2)\n",
    "    \n",
    "print(cv_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validated R^2\n",
      "Mean:\t0.7202568091232989\n",
      "Std.:\t0.04285289109219576\n"
     ]
    }
   ],
   "source": [
    "# Get the mean and standard deviation of the cross-validation test set performance across folds\n",
    "cv_r2 = np.array(cv_r2)\n",
    "print(f'Cross-validated R^2\\nMean:\\t{cv_r2.mean()}\\nStd.:\\t{cv_r2.std()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Notice that this test set performance is actually lower than in our initial example when we split the\n",
    "dataset once into a train/test set. We should trust this estimate more, because it was computed\n",
    "from 5 different train/test splits rather than a single one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**THINK:** Are we taking into consideration the Golden Rule here?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### sklearn provides an [easy](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html) way to do cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validated R^2\n",
      "Mean:\t0.7202568091232989\n",
      "Std.:\t0.04285289109219576\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# List that will accumulate test performance on each fold\n",
    "cv_r2 = []\n",
    "\n",
    "kf = KFold(n_splits=k_folds)\n",
    "\n",
    "for train_idx, test_idx in kf.split(X):\n",
    "    X_train, X_test, y_train, y_test = X[train_idx], X[test_idx], y[train_idx], y[test_idx]\n",
    "    \n",
    "    # Train the model\n",
    "    reg.fit(X_train, y_train)\n",
    "    \n",
    "    # Evaluate the model on the test set\n",
    "    y_pred = reg.predict(X_test)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    cv_r2.append(r2)\n",
    "    \n",
    "# Get the mean and standard deviation of the cross-validation test set performance across folds\n",
    "cv_r2 = np.array(cv_r2)\n",
    "print(f'Cross-validated R^2\\nMean:\\t{cv_r2.mean()}\\nStd.:\\t{cv_r2.std()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### And an even [easier way](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html) that even gets you the scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validated R^2\n",
      "Mean:\t0.7202568091232989\n",
      "Std.:\t0.04285289109219576\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "cv_r2 = cross_val_score(reg, X, y, cv=k_folds, scoring='r2')\n",
    "print(f'Cross-validated R^2\\nMean:\\t{cv_r2.mean()}\\nStd.:\\t{cv_r2.std()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Hyperparameter tuning\n",
    "- Most models often have parameters that we must set, which are not learned during training. We call these **hyperparameters**\n",
    "- For instance, Ridge Regression, which uses L2 regularization to prevent overfitting, requires us to set a λ parameter that balances the weight penalty vs. prediction error in the loss term\n",
    "- If these hyperparameters are not learned during training, how do we learn them?\n",
    "- The most common method amounts to, disappointingly, guess-and-check... We try a bunch of values for the hyperparameters and set them to whatever achieves the lowest loss\n",
    "    - Common techniques: grid search, random search\n",
    "    - More advanced techniques (that we won't look at): Bayesian optimization, genetic algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Grid search with cross-validation\n",
    "- For each hyperparameter, specify a list of values we want to try\n",
    "- Train a version of the model using each *combination* of hyperparameters\n",
    "- Whichever combination achieves the lowest loss will be picked\n",
    "\n",
    "<img src=\"images/grid_search.png\" style=\"width: 1000px;\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Our hyperparameters are often selected to prevent overfitting (e.g. λ for L2 regularization, learning rate, etc.)\n",
    "- To select the best hyperparameters that prevent overfitting, we should be selecting the ones that give the best performance on some held out data\n",
    "- For that reason, grid search is frequently combined with cross-validation, and we pick the hyperparameters that gave the best average validation performance across folds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Grid search with cross-validation example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best hyperparameter settings achieve a cross-validated\n",
      "R^2     : 0.7207\n",
      "Alpha   : 0.01\n",
      "L1 ratio: 0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# Scale features since weight magnitudes will effect regularization weight penalties\n",
    "X_scaled = StandardScaler().fit_transform(X)\n",
    "# Hyperparameter settings we want to try\n",
    "alphas = [0.001, 0.01, 0.1, 1]\n",
    "l1_ratios = [0, 0.25, 0.5, 0.75, 1]\n",
    "# Keep track of the best hyperparameters found so far\n",
    "best_r2 = -np.inf\n",
    "best_alpha = None\n",
    "best_l1_ratio = None\n",
    "\n",
    "for alpha in alphas:\n",
    "    for l1_ratio in l1_ratios:\n",
    "        model = ElasticNet(alpha=alpha, l1_ratio=l1_ratio, random_state=27)\n",
    "        cv_r2 = cross_val_score(model, X_scaled, y, cv=k_folds, scoring='r2')\n",
    "        if cv_r2.mean() > best_r2:\n",
    "            best_r2 = cv_r2.mean()\n",
    "            best_alpha = alpha\n",
    "            best_l1_ratio = l1_ratio           \n",
    "print(f'The best hyperparameter settings achieve a cross-validated\\n\\\n",
    "R^2     : {round(best_r2,4)}\\n\\\n",
    "Alpha   : {best_alpha}\\n\\\n",
    "L1 ratio: {best_l1_ratio}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### As always, sklearn provides an [easier way](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best hyperparameter settings achieve a cross-validated\n",
      "R^2     : 0.7206816828526261\n",
      "Alpha   : 0.01\n",
      "L1 ratio: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    2.9s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    3.0s finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Make a dictionary with model arguments as keys and lists of grid settings as values\n",
    "param_grid = {\n",
    "              'alpha': [0.001, 0.01, 0.1, 1],\n",
    "              'l1_ratio': [0, 0.25, 0.5, 0.75, 1]\n",
    "              }\n",
    "\n",
    "grid = GridSearchCV(estimator = model, \n",
    "                    param_grid = param_grid,\n",
    "                    cv = k_folds, \n",
    "                    scoring = 'r2', \n",
    "                    verbose=1, n_jobs=-1) # verbose=1 -> print results, n_jobs=-1 -> use all processors in parallel\n",
    "\n",
    "grid_result = grid.fit(X_scaled, y)\n",
    "\n",
    "best_r2 = grid_result.best_score_\n",
    "best_alpha = grid_result.best_params_['alpha']\n",
    "best_l1_ratio = grid_result.best_params_['l1_ratio']\n",
    "\n",
    "print(f'The best hyperparameter settings achieve a cross-validated\\n\\\n",
    "R^2     : {best_r2}\\n\\\n",
    "Alpha   : {best_alpha}\\n\\\n",
    "L1 ratio: {best_l1_ratio}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Train / validation / test split\n",
    "\n",
    "**Question**: Have you noticed anything wrong with what we are doing? Should we trust our cross-validation score as a true estimate of performance on out-of-sample data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "We cannot trust it. We have been using the cross-validation score to select hyperparameters. You can think of this as having used the validation data in each fold to train our model in a way. So, our model will be biased to the dataset and our cross-validation score will be overly-optimistic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Solution**:\n",
    "1. Split the dataset into a train/test set\n",
    "2. Perform grid search with cross-validation on the training set. Each fold, the training set will be split into a train/validation set\n",
    "3. Using the hyperparameters that obtained the best cross-validation score, retrain the model on the entire training set (not just training folds within this training set)\n",
    "4. Evaluate the model on the test set to get a true estimate of the out-of-sample error\n",
    "\n",
    "<img src=\"images/cross_validation_with_test.png\" style=\"width: 500px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Even then, we are violating our rule. It won't mess up your model terribly so, for now, we will proceed that way. However, in a future lesson you will learn about Pipelines. Pay attention there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "The best hyperparameter settings achieve a cross-validated\n",
      "R^2     : 0.7171522166211203\n",
      "Alpha   : 0.01\n",
      "L1 ratio: 0\n",
      "R^2 on the test set:\t0.725493932307976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    0.2s finished\n"
     ]
    }
   ],
   "source": [
    "# Split data into a train and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, shuffle=False, train_size=0.8)\n",
    "\n",
    "param_grid = {\n",
    "              'alpha': [0.001, 0.01, 0.1, 1],\n",
    "              'l1_ratio': [0, 0.25, 0.5, 0.75, 1]\n",
    "              }\n",
    "\n",
    "# Standardize the data using only statistics from the training set\n",
    "# (always assume no knowledge of the test set for most unbiased performance estimate)\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, cv=k_folds, scoring='r2', verbose=1, n_jobs=-1) # verbose=1 -> print results, n_jobs=-1 -> use all processors in parallel\n",
    "grid_result = grid.fit(X_train, y_train)\n",
    "\n",
    "best_r2 = grid_result.best_score_\n",
    "best_alpha = grid_result.best_params_['alpha']\n",
    "best_l1_ratio = grid_result.best_params_['l1_ratio']\n",
    "print(f'The best hyperparameter settings achieve a cross-validated\\n\\\n",
    "R^2     : {best_r2}\\n\\\n",
    "Alpha   : {best_alpha}\\n\\\n",
    "L1 ratio: {best_l1_ratio}')\n",
    "\n",
    "\n",
    "# Using the best hyperparameters, retrain on the entire train set and evaluate on the test set\n",
    "best_model = grid_result.best_estimator_    # Sklearn automatically retrains the model on the whole training set following cross-validation using the best hyperparameters\n",
    "y_pred = best_model.predict(X_test)\n",
    "r2_test = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f'R^2 on the test set:\\t{r2_test}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Model evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Classification\n",
    "- **Goal**: Predict between two or more discrete classes. For between two classes, called *binary* classification\n",
    "- **Example**: Predict whether or not someone has cancer (binary), predict what object is shown in an image (multiclass)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### Accuracy\n",
    "$$acc = \\frac{\\text{# of times correct}}{\\text{# of predictions made}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Confusion matrix\n",
    "Full detail about how model fails\n",
    "\n",
    "| | Actual + | Actual - |\n",
    "|-|-|-|\n",
    "|Predicted + | True Positive | False Positive | \n",
    "|Predicted - | False Negative | True Negative |\n",
    "\n",
    "<img src=\"images/multiclass_confusion_matrix.png\" style=\"width: 300px; display: block; margin-left: auto; margin-right: auto\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### In a binary case of 100 examples (50+, 50-), 95% accuracy:\n",
    "\n",
    "| | Actual + | Actual - |\n",
    "|-|-|-|\n",
    "|Predicted + | 50| 5 | \n",
    "|Predicted - |0 | 45|\n",
    "\n",
    "| | Actual + | Actual - |\n",
    "|-|-|-|\n",
    "|Predicted + | 45| 0 | \n",
    "|Predicted - |5 | 50|\n",
    "\n",
    "- Which model would you rather have predicting...\n",
    "    - **cancer diagnosis**? (positive means \"has cancer\")\n",
    "    - **spam filtering**? (positive means \"is spam\")\n",
    "    \n",
    "**Conclusion**: How your model fails matters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Metrics computed from binary confusion matrix\n",
    "\n",
    "#### Recall: True positives / Condition positive\n",
    "- We want high recall when we don't want to miss any positive conditions\n",
    "- Good for something like cancer diagnosis\n",
    "\n",
    "#### Precision: True positives / Detected or predicted positives\n",
    "- We want high precision if the machine learning model is going to trigger some automated process\n",
    "- Good for something like spam detection\n",
    "- Low precision may be okay in cancer diagnosis, just run another test\n",
    "\n",
    "#### F1 score: 2 * (Precision * Recall) / (Precision + Recall)\n",
    "- Combine both precision and recall into a single general-purpose metric\n",
    "- Useful for quickly comparing models\n",
    "- There are variations that weight precision/recall unequally"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Regression\n",
    "\n",
    "### Mean Squared Error\n",
    "- Commonly used (especially as training loss)\n",
    "- Large errors (from outliers) have disproportionate impact\n",
    "- Units not intuitive\n",
    "- Task-dependent (i.e. no maximum bound)\n",
    "\n",
    "\\begin{align}\n",
    "    MSE &= \\frac{1}{n} \\sum_{i=0}^n (y_i - \\hat{y}_i)^2 \\\\\n",
    "        &= \\frac{1}{n} (\\mathbf{y} - \\mathbf{\\hat{y}})^T (\\mathbf{y} - \\mathbf{\\hat{y}})\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Root Mean Squared Error\n",
    "- Commonly used for evaluation, but not for training loss\n",
    "- Large errors (from outliers) have disproportionate impact\n",
    "- Units are intuitive\n",
    "- Task-dependent (i.e. no maximum bound)\n",
    "\n",
    "\\begin{align}\n",
    "    RMSE &= \\sqrt{\\frac{1}{n} \\sum_{i=0}^n (y_i - \\hat{y}_i)^2} \\\\\n",
    "         &= \\sqrt{\\frac{1}{n} (\\mathbf{y} - \\mathbf{\\hat{y}})^T (\\mathbf{y} - \\mathbf{\\hat{y}})}\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Mean Absolute Error \n",
    "- Commonly used (especially as training loss, but less than Mean Squared Error)\n",
    "- Outliers have less impact\n",
    "- Units are intuitive\n",
    "- Task-dependent (i.e. no maximum bound)\n",
    "\n",
    "\\begin{align}\n",
    "    MAE &= \\frac{1}{n} \\sum_{i=0}^n |y_i - \\hat{y}_i|\n",
    "\\end{align}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Coefficient of Determination ($R^2$)\n",
    "- Measures the proportion of the variation in your dependent variable (Y) explained by your independent variables (X)\n",
    "- Commonly used for evaluation, but not for training loss\n",
    "- Intuitive interpretation\n",
    "- Task-independent (usually ranges from 0 to 1, although negative values can mean worse than most naive solution)\n",
    "- *Adjusted $R^2$* variant adjusts the statistic based on the number of independent variables in the model\n",
    "\n",
    "\\begin{align}\n",
    "    R^2 &= 1 - \\frac{\\text{Unexplained variance}}{\\text{Total variance}} \\\\\n",
    "        &= 1 - \\frac{MSE_{model}}{MSE_{baseline}} \\\\\n",
    "        &= 1 - \\frac{(\\mathbf{y} - \\mathbf{\\hat{y}})^T (\\mathbf{y} - \\mathbf{\\hat{y}})}{(\\mathbf{y} - \\mathbf{y}_{avg})^T (\\mathbf{y} - \\mathbf{y}_{avg})}\n",
    "\\end{align}"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
