{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Lighthouse Labs - Synaptive Medical\n",
    "\n",
    "### W7D7 Deep Learning and Convolutional Neural Networks (CNNs)\n",
    "\n",
    "Instructor: Socorro Dominguez  \n",
    "February 23, 2021"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Agenda:**\n",
    "\n",
    "- CNNs\n",
    "- What kind of layers CNN have?\n",
    "    - Convolution\n",
    "    - Pooling\n",
    "    - Flattening\n",
    "    - Full connection\n",
    "     \n",
    "- Case Studies of different CNN algorithms. \n",
    "\n",
    "- CNN tutorial\n",
    "\n",
    "- Intro to RNNs and Special Case LSTMs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## What is a CNN?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "\n",
    "![img](img/CNNnews.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    ".... not that CNN....\n",
    "\n",
    "This CNN:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "![img](img/CNN.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "CNNs most common task is Computer Vision.\n",
    "\n",
    "* Sports:\n",
    "    * Player Tracking\n",
    "    * Ball Tracking\n",
    "\n",
    "* Health and Medicine:\n",
    "    * Cancer / Tumor Detection\n",
    "    * Cell Classification\n",
    "    * Movement Analysis for neurological and musculoskeletal diseases\n",
    "\n",
    "* Agriculture and farming:\n",
    "    * Plant Recognition.\n",
    "    * Farm Automation\n",
    "    * Animal Monitoring\n",
    "\n",
    "* Transportation,  Oiling and mining, many others!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Convolutional Neural Networks are a type of Deep Learning Algorithm.\n",
    "\n",
    "1. CNNs take an image as an input.\n",
    "2. CNNs learn the features of the image through filters. \n",
    "3. They identify important objects present in the image, allowing them to learn to discern one image from the other.\n",
    "\n",
    "In our walkthrough, the CNN will learn specific features of cats that differentiate them from the dogs. \n",
    "Then, when it is provided input of cats and dogs, it can differentiate between the two. \n",
    "\n",
    "! During cold-start, the filters \"require\" hand engineering but with progress in training, they are able to adapt to the learned features and develop filters of their own. CNNs are continuously evolving."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![img](img/robot.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* CNNs output is usually probabilities of being something. \n",
    "\n",
    "* A CNN is a special tries to reduce the number of parameters in a deep neural network with many units without losing too much in the quality of the model. \n",
    "\n",
    "* In images, pixels that are close to one another usually have the same type of information: sky, water, leaves, etc. \n",
    "\n",
    "* The exception from the rule are **the edges**: the parts of an image where two different objects “touch” one another."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* The neural network is trained to recognize regions of the same information as well as the edges. This would allow to predict the object represented in the image. \n",
    "\n",
    "* **Example:** If the neural network detected multiple skin regions and edges that look like parts of an oval with skin-like tone on the inside and bluish tone on the outside, then it is likely that it’s a face on a sky background. \n",
    "    * If the goal is to detect people on pictures, the neural network will most likely succeed in predicting a person in this picture."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**The most important information in the image is local**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "How does a CNN work?\n",
    "- We split the image into square patches using a moving window approach. \n",
    "- We can train multiple smaller regression models at once, each regression model receives a square patch as input.\n",
    "    - We train the 'filters'.\n",
    "- Each regression model's work is to learn to detect a specific kind of pattern in the input patch. \n",
    "\n",
    "For example, one small regression model will learn to detect the sky; another one will detect the grass, the third one will detect edges of a building."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* CNNs perform similarly to an ordinary fully connected Neural Networks. \n",
    "    * They have weights and biases that are learned from the input. \n",
    "    * Every neuron connected in the network receives an input and performs a dot product on it. \n",
    "    * There is a function at the end that consists of scores that we obtain from the various layers. \n",
    "    * They have a loss function at the end to evaluate performance. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![img](img/anatomyofcnn.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "What seems different\n",
    "\n",
    "![](https://upload.wikimedia.org/wikipedia/commons/4/46/Colored_neural_network.svg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The first architecture is more practical manner. \n",
    "\n",
    "There is no linear arrangement of neurons. CNN's neurons have a structure of three dimensions – Length, Width, and Height. \n",
    "\n",
    "For instance, Dogs and Cats images are dimensions 32x32x3 and the final output will have a singular vector of the images of dimensions 1x1x2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![](img/3channels.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The goal:  Reduce the images into an easier form to process, without losing features which are critical for getting a good prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**ARCHITECTURE**\n",
    "\n",
    "* INPUT – A typical image dataset will hold images if dimensions l x w x d, where the depth denotes the number of channels (RGB) in the image.\n",
    "  \n",
    "  \n",
    "* CONV layer - computes the dot product between the weights of the neuron and the region of the input image to which share a connection. An example would be 32x32x12 denoting the 12 filters which the neural network makes use of.\n",
    "  \n",
    "  \n",
    "* The third layer consists of RELU which (activation function) to our resultant dot product. \n",
    "  \n",
    "  \n",
    "* The fourth layer is a POOLing layer, it downsamples the spatial dimensions of the image (width and height).\n",
    "  \n",
    "  \n",
    "* The fully connected layer will compute the class score, leading to a final volume of 1 x 1 x n; where n is the number of categories to classify."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The convolutional component comprises the learnable filter.  \n",
    "\n",
    "* To detect some pattern, a small regression model has to learn the parameters of a matrix F (for “filter”) of size p × p, where p is the size of a patch.\n",
    "\n",
    "\n",
    "* If we had for input a black and white image, 1 would represent the black and 0 would represent the white pixels. \n",
    "* Assume 3x3 pixels patches (p = 3). Some patch could then look like the following matrix P (for “patch”):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$$P = \\begin{bmatrix} 0 & 1 & 0 \\\\ 1 & 1 & 1 \\\\ 0 & 1 & 0 \\end{bmatrix}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The previous patch represents a pattern that looks like a cross. \n",
    "\n",
    "The small regression model that will detect such patterns (and only them) would need to learn a 3 by 3 parameter matrix F where parameters at positions corresponding to the 1s in the input patch would be positive numbers, while the parameters in positions corresponding to 0s would be close to zero. \n",
    "\n",
    "If we calculate the convolution of matrices P and F, the value we obtain is higher the more similar F is to P. To illustrate the convolution of two matrices, assume that F looks like this:\n",
    "\n",
    "$$F = \\begin{bmatrix} 0 & 2 & 3 \\\\ 2 & 4 & 1 \\\\ 0 & 3 & 0 \\end{bmatrix}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Then convolution operator is only defined for matrices that have the same number of rows and columns. For our matrices of P and F it’s calculated as illustrated below:\n",
    "\n",
    "![convolution](img/02_Convolution.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "If our patch had a different pattern, then the convolution with F would give a different result. \n",
    "\n",
    "*The more the patch “looks” like the filter, the higher the value of the convolution operation is*\n",
    "\n",
    "For convenience, there’s also a bias parameter b associated with each filter F which is added to the result of a\n",
    "convolution before applying the nonlinearity (activation function)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "One layer of a CNN consists of multiple convolution filters (each with its own bias parameter).\n",
    "\n",
    "Each filter of the first layer slides — or convolves — across the input image, left to right, top to bottom, and convolution is computed at each iteration.\n",
    "\n",
    "Like this:\n",
    "\n",
    "![](https://miro.medium.com/max/1400/1*ciDgQEjViWLnCbmX-EeSrA.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![](https://i.stack.imgur.com/FjvuN.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "If the CNN has one convolution layer following another convolution layer, then the subsequent layer *l + 1* treats the output of the preceding layer *l* as a collection of size *l* image matrices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Pooling**\n",
    "\n",
    "This is a technique very often used in CNNs. Pooling works in a way very similar to convolution, as a filter applied using amoving window approach. \n",
    "\n",
    "Instead of applying a trainable filter to an input matrix, a pooling layer applies a fixed operator, usually either max or average. \n",
    "\n",
    "Pooling's hyperparameters are also the size of the filter and the stride. \n",
    "\n",
    "Usually, a pooling layer follows a convolution layer, and it gets the output of convolution as input. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Pooling does not have parameters to learn. It also contributes to the increased accuracy of the model and improves the speed of training by reducing the number of parameters of the neural network.\n",
    "![pooling](https://miro.medium.com/max/792/1*uoWYsCV5vBU8SHFPAPao-w.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Why ReLU as Normalization Technique\n",
    "\n",
    "After getting the new convolved matrix, anything negative is turned to zero.\n",
    "\n",
    "This removes unnecessary noise. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Hyperparameters:\n",
    "* **Stride** Choose how big you want the step to be for the pooling, conv layers\n",
    "* **Padding** Add zeros around the image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## What a CNN looks like after all?\n",
    "\n",
    "![img](img/05_FullCNN.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![img](img/mnistcnn.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check out this video to understand more: https://www.youtube.com/watch?v=FmpDIaiMIeA&feature=emb_title"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Introduction to RNNs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### Example of a Use Case\n",
    "\n",
    "[Music Generator](https://magenta.tensorflow.org/performance-rnn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Motivation to know about RNNs\n",
    "\n",
    "- Language is an inherently sequential phenomenon.\n",
    "- Reflected in the metaphors used to describe language\n",
    "- flow of conversation, news feeds, and twitter streams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Sentiment analysis using feed-forward neural networks**\n",
    "\n",
    "* In feed-forward neural networks, all connections flow forward (no loops).\n",
    "* Each layer of hidden units is fully connected to the next.\n",
    "* We need to pass fixed sized vector representation of text (CountVectorizer object) as input.\n",
    "* We lose the temporal aspect of text in this representation.\n",
    "\n",
    "![img](https://learnopencv.com/wp-content/uploads/2017/10/mlp-diagram.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Language modeling: Why should we care?\n",
    "\n",
    "### Powerful idea in NLP and helps in many tasks.\n",
    "\n",
    "* Machine translation:\n",
    "> P(In the age of data algorithms have the answer) > P(the age data of in algorithms answer the have)\n",
    "\n",
    "* Spelling correction\n",
    "> My office is a 10  <span style=\"color:red\">minuet</span> bus ride from my home.  \n",
    "> P(10 <span style=\"color:blue\">minute</span> bus ride from my home) > P(10 <span style=\"color:red\">minuet</span> bus ride from my home)\n",
    "\n",
    "* Speech recognition\n",
    "> P(<span style=\"color:blue\">I read</span> a book) > P(<span style=\"color:red\">Eye red</span> a book)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Motivation: Language modeling task\n",
    "\n",
    "In the beginning, NLP used a lot of Markov Chains. If you are really interested in learning NLP, you should study Markov Chains.\n",
    "\n",
    "Markov model: $P(w_t|w_1,w_2,\\dots,w_{t-1}) = P(w_t|w_{t-1})$\n",
    "\n",
    "Markov model with more context: $P(w_t|w_1,w_2,\\dots,w_{t-1}) = P(w_t|w_{t-2}, w_{t-1})$\n",
    "\n",
    "\n",
    "**Markov Models Downsides:**\n",
    "* They are 'memoryless'. They do not have memory beyond the previous maximum $n$ steps and when $n$ becomes larger, there is sparsity problem.\n",
    "\n",
    "* They have huge RAM requirements because you have to store all ngrams.\n",
    "\n",
    "* A Markov model with $n=5$ would probably not be able to predict the next correct words in the following cases.\n",
    "    * I am studying DS at Lighthouse because I want to work as a Data Scientist.\n",
    "    * I am studying law at UBC because I want to work as a lawyer.\n",
    "    * I am studying Actuarial Science at Waterloo because I want to work as an Actuary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## RNNs motivation\n",
    "* RNNs can help us with this limited memory problem!\n",
    "* RNNs are a kind of neural network model which use hidden units to remember things over time.\n",
    "* Condition the neural network on all previous words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### RNN intuition: Example\n",
    "\n",
    "- Put a number of feedforward networks together.\n",
    "- Suppose I have 1 word represented by a vector of size 4 and I want to predict something about that word, I use one feedforward neural network. \n",
    "- Suppose I have 2 words, I use 2 of these networks and put them together. \n",
    "\n",
    "<img src=\"img/RNN_two_feedforward.png\" height=\"800\" width=\"800\"> \n",
    "\n",
    "\n",
    "(Image credit: [learnopencv](https://www.learnopencv.com/understanding-feedforward-neural-networks/))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### RNN intuition\n",
    "\n",
    "- Put a number of feedforward networks together. \n",
    "- Make connections between the hidden layers.\n",
    "- Process sequences by presenting one element at a time to the network.\n",
    "\n",
    "\n",
    "<img src=\"img/RNN_introduction.png\" height=\"800\" width=\"800\"> \n",
    "\n",
    "(Credit: [Stanford CS224d slides](http://cs224d.stanford.edu/lectures/CS224d-Lecture8.pdf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## RNN as a graphical model\n",
    "\n",
    "- Each state is a function of the previous state and the input.\n",
    "- A state contains information about the whole past sequence. \n",
    "    - $s_t = g_t(x_t, x_{t-1}, \\dots, x_2, x_1)$ \n",
    "\n",
    "<img src=\"img/RNN_dynamic_model.png\" height=\"800\" width=\"800\"> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Parameter sharing\n",
    "\n",
    "- Parameters\n",
    "    - Input to hidden weight matrix: $U$\n",
    "    - Hidden to output weight matrix: $V$    \n",
    "    - Hidden to hidden weight matrix: $W$\n",
    "    \n",
    "- **We share all weights between time steps**    \n",
    "\n",
    "<img src=\"img/RNN_dynamic_model.png\" height=\"800\" width=\"800\"> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### What can we do with RNNs?\n",
    "\n",
    "- Simple or Vanilla RNN\n",
    "\n",
    "<img src=\"img/RNN_introduction.png\" height=\"800\" width=\"800\"> \n",
    "\n",
    "- But a number of architectures are possible, which makes them a very rich family of models.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "One to one \n",
    "\n",
    "- The usual feedforward neural network \n",
    "\n",
    "One to many\n",
    "\n",
    "- Music generation\n",
    "- Text generation\n",
    "- Image captioning \n",
    "\n",
    "Many to one\n",
    "\n",
    "- Sentiment analysis\n",
    "- Text classification \n",
    "- Video activity recognition \n",
    "\n",
    "Many to many (sequence to sequence or encoder-decoder models)\n",
    "\n",
    "- Speech recognition \n",
    "- Machine translation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### RNN architectures\n",
    "\n",
    "- A number of possible RNN architectures\n",
    "\n",
    "<img src=\"img/RNN_architectures.png\" height=\"1000\" width=\"1000\"> \n",
    "\n",
    "[source](http://cs231n.stanford.edu/slides/2017/cs231n_2017_lecture10.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Mini Intro to LSTMs\n",
    "\n",
    "* RNNs tend to have a problem called The Vanishing Gradient."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### A robust solution to this problem is \n",
    "\n",
    "- **Use a more complex recurrent unit with gates**\n",
    "    - Gated Recurrent Units (GRUs)    \n",
    "    - **Long Short Term Memory networks (LSTMs)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Long Short Term Memory networks (LSTMs)\n",
    "\n",
    "- [Invented in 1997](https://www.bioinf.jku.at/publications/older/2604.pdf) by Hochreiter and Schmidhuber. \n",
    "- Designed so that model can remember things for a long time (hundreds of time steps)! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### LSTM for image captioning \n",
    "\n",
    "<img src=\"img/RNN_LSTM_image_captioning.png\" height=\"2000\" width=\"2000\"> \n",
    "\n",
    "\n",
    "(Credit: [LSTMs for image captioning](https://arxiv.org/pdf/1411.4555.pdf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Long Short Term Memory networks (LSTMs)\n",
    "\n",
    "- In an LSTM, the repeating module is more complicated. \n",
    "- It selectively controls the flow of information using gates. \n",
    "\n",
    "- In addition to usual hidden units, LSTMs have memory cells. \n",
    "- Purpose of memory cells is to remember things for a long time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### LSTMs: The core idea \n",
    "\n",
    "- The core idea in LSTMs is using a cell state (memory cell)\n",
    "- Information can flow along the memory unchanged. \n",
    "- Information can be removed or written to the cells regulated by gates. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
